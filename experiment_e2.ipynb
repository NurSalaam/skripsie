{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/seaborn/utils.py:61: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  fig.canvas.draw()\n",
      "/tmp/ipykernel_48492/21101144.py:135: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  plt.savefig('final_visualisations/experiment_2/performance_improvement_heatmap.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
      "/tmp/ipykernel_48492/21101144.py:135: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n",
      "  plt.savefig('final_visualisations/experiment_2/performance_improvement_heatmap.pdf', format='pdf', dpi=300, bbox_inches='tight')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "from cycler import cycler\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# Paths to the Computer Modern font files\n",
    "font_paths = {\n",
    "    'serif': 'assets/fonts/cmunrm.ttf',\n",
    "    'italic': 'assets/fonts/cmunti.ttf',\n",
    "    'bold': 'assets/fonts/cmunbx.ttf',\n",
    "    'bold_italic': 'assets/fonts/cmunbi.ttf'\n",
    "}\n",
    "\n",
    "# Add the fonts to Matplotlib\n",
    "for key, path in font_paths.items():\n",
    "    fm.fontManager.addfont(path)\n",
    "\n",
    "# Set the font properties globally\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['CMU Serif']\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Monochrome color cycle\n",
    "monochrome = (cycler('color', ['k']) * cycler('linestyle', ['-', '--', ':', '-.']))\n",
    "rcParams['axes.prop_cycle'] = monochrome\n",
    "\n",
    "# Function to format titles (only first letter capitalized)\n",
    "def format_title(title):\n",
    "    return title.capitalize()\n",
    "\n",
    "# Function to add subfigure labels\n",
    "def add_subfigure_label(ax, label):\n",
    "    ax.text(-0.1, 1.1, f'({label})', transform=ax.transAxes, fontsize=14, fontweight='bold', va='top')\n",
    "\n",
    "# ... rest of your code\n",
    "\n",
    "# Helper function to create unique method names\n",
    "def get_unique_method_name(method, params):\n",
    "    if method == 'wv_ols_r2':\n",
    "        return f\"wv_ols_r2_{str(params.get('emphasize_diversity', False))[0]}\"\n",
    "    elif method == 'hard_voting':\n",
    "        return f\"hard_voting_{str(params.get('gaussian', False))[0]}\"\n",
    "    elif params:\n",
    "        param_str = '_'.join(f\"{k}_{v}\" for k, v in sorted(params.items()))\n",
    "        return f\"{method}_{param_str}\"\n",
    "    return method\n",
    "\n",
    "# Load the data\n",
    "e1_results = pd.read_csv('final_experiments/experiment_e1_results.csv')\n",
    "e2_results = pd.read_csv('final_experiments/experiment_e2_results.csv')\n",
    "e2_summary = pd.read_csv('final_experiments/experiment_e2_summary.csv')\n",
    "\n",
    "# Load configurations\n",
    "with open('final_experiments/experiment_e2_configurations.json', 'r') as f:\n",
    "    e2_configs = json.load(f)\n",
    "\n",
    "# Create unique method names\n",
    "e2_results['unique_method'] = e2_results.apply(lambda row: get_unique_method_name(row['ensemble_method'], json.loads(row['method_params'])), axis=1)\n",
    "e2_summary['unique_method'] = e2_summary.apply(lambda row: get_unique_method_name(row['ensemble_method'], json.loads(row['method_params'])), axis=1)\n",
    "\n",
    "# Calculate relative performance for each ensemble\n",
    "relative_performances = []\n",
    "for config in e2_configs:\n",
    "    bl_type = config['base_learner_type']\n",
    "    method = config['ensemble_method']\n",
    "    rep = config['repetition']\n",
    "    constituent_scores = [e1_results[(e1_results['base_learner'] == bl_type) & \n",
    "                                     (e1_results['params'] == str(params))]['ucr_score'].values[0]\n",
    "                          for params in config['base_learner_params']]\n",
    "    avg_constituent_score = np.mean(constituent_scores)\n",
    "    unique_method = get_unique_method_name(method, config['method_params'])\n",
    "    ensemble_data = e2_results[(e2_results['base_learner_type'] == bl_type) & \n",
    "                               (e2_results['unique_method'] == unique_method) & \n",
    "                               (e2_results['repetition'] == rep)]\n",
    "    ensemble_score = ensemble_data['ucr_score'].values[0]\n",
    "    computational_time = ensemble_data['computational_time'].values[0]\n",
    "    relative_score = ensemble_score / avg_constituent_score\n",
    "    relative_performances.append({\n",
    "        'base_learner_type': bl_type,\n",
    "        'unique_method': unique_method,\n",
    "        'repetition': rep,\n",
    "        'relative_score': relative_score,\n",
    "        'ensemble_score': ensemble_score,\n",
    "        'avg_constituent_score': avg_constituent_score,\n",
    "        'computational_time': computational_time\n",
    "    })\n",
    "\n",
    "relative_df = pd.DataFrame(relative_performances)\n",
    "\n",
    "\n",
    "\n",
    "# 1. Comparative Box Plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 15))\n",
    "base_learners = e2_results['base_learner_type'].unique()\n",
    "for i, bl in enumerate(base_learners):\n",
    "    ax = axs[i // 2, i % 2]\n",
    "    data = []\n",
    "    labels = []\n",
    "    for method in relative_df['unique_method'].unique():\n",
    "        data.append(relative_df[(relative_df['base_learner_type'] == bl) & \n",
    "                                (relative_df['unique_method'] == method)]['relative_score'])\n",
    "        labels.append(method)\n",
    "    ax.boxplot(data, labels=labels)\n",
    "    ax.axhline(y=1, color='k', linestyle='--')\n",
    "    ax.set_title(format_title(f'{bl} - ensemble methods'))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Relative score')\n",
    "    add_subfigure_label(ax, chr(97 + i))  # 'a', 'b', 'c', 'd'\n",
    "\n",
    "fig.suptitle(format_title('Comparative performance of ensemble methods'), fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_visualisations/experiment_2/comparative_box_plots.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 2. Performance Improvement Heatmap\n",
    "improvement_data = relative_df.groupby(['base_learner_type', 'unique_method'])['relative_score'].mean().reset_index()\n",
    "improvement_pivot = improvement_data.pivot(index='base_learner_type', columns='unique_method', values='relative_score')\n",
    "improvement_pivot = (improvement_pivot - 1) * 100  # Convert to percentage improvement\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 12))\n",
    "sns.heatmap(improvement_pivot, annot=True, fmt='.2f', cmap='Greys', ax=ax)\n",
    "\n",
    "ax.set_title(format_title('Average performance improvement of ensemble methods (%)'))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "add_subfigure_label(ax, 'a')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_visualisations/experiment_2/performance_improvement_heatmap.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment E2 completed. Results saved to 'final_experiments/experiment_e2_results.csv', 'final_experiments/experiment_e2_configurations.json', and 'final_experiments/experiment_e2_summary.csv'.\n"
     ]
    }
   ],
   "source": [
    "# import cudf.pandas\n",
    "# cudf.pandas.install()\n",
    "\n",
    "# import pyscamp\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# import random\n",
    "# import os\n",
    "# import json\n",
    "\n",
    "# from lof import LocalOutlierFactor\n",
    "# from matrix_profile import MatrixProfile\n",
    "# from isolation_forest import IsolationForest\n",
    "# from kmeans import KMeans\n",
    "# from ensemble_detector import EnsembleDetector\n",
    "# from dataloader import DataLoader\n",
    "# from benchmarker import benchmark\n",
    "\n",
    "# # Constants\n",
    "# UCR_PATH = 'ucrdata'\n",
    "# CACHED_SCORES_DIR = 'final_scores'\n",
    "# RESULTS_DIR = 'final_results'\n",
    "# ENSEMBLE_RESULTS_DIR = 'final_ensembles/results'\n",
    "# ENSEMBLE_SCORES_DIR = 'final_ensembles/scores'\n",
    "# N_REPETITIONS = 30\n",
    "# ENSEMBLE_SIZE =16\n",
    "\n",
    "# # Base learner configurations\n",
    "# BASE_LEARNERS = {\n",
    "#     'LOF': {\n",
    "#         'class': LocalOutlierFactor,\n",
    "#         'params': [\n",
    "#             {'windowSize': ws, 'neighbors': n, 'gpu': True}\n",
    "#             for ws in [25, 50, 100, 150, 200]\n",
    "#             for n in [10, 20, 50, 100]\n",
    "#         ]\n",
    "#     },\n",
    "#     'IF': {\n",
    "#         'class': IsolationForest,\n",
    "#         'params': [\n",
    "#             {'windowSize': ws}\n",
    "#             for ws in [20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700]\n",
    "#         ]\n",
    "#     },\n",
    "#     'KMeans': {\n",
    "#         'class': KMeans,\n",
    "#         'params': [\n",
    "#             {'windowSize': ws, 'n_clusters': nc}\n",
    "#             for ws in [50, 100, 200, 500]\n",
    "#             for nc in [10, 20, 50, 100, 200]\n",
    "#         ]\n",
    "#     },\n",
    "#     'MP': {\n",
    "#         'class': MatrixProfile,\n",
    "#         'params': [\n",
    "#             {'windowSize': ws}\n",
    "#             for ws in [20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700]\n",
    "#         ]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Ensemble methods\n",
    "# ENSEMBLE_METHODS = [\n",
    "#     ('simple_average', {}),\n",
    "#     ('maximum_score', {}),\n",
    "#     ('wv_ols', {}),\n",
    "#     ('wv_ols_r2', {'emphasize_diversity': False}),\n",
    "#     # ('wv_ols_r2', {'emphasize_diversity': True}),\n",
    "#     ('hard_voting', {'spread_window': 100, 'gaussian': False}),\n",
    "#     ('hard_voting', {'spread_window': 100, 'gaussian': True})\n",
    "\n",
    "# ]\n",
    "\n",
    "# def create_homogeneous_ensemble(base_learner_type, n=ENSEMBLE_SIZE):\n",
    "#     base_learner_class = BASE_LEARNERS[base_learner_type]['class']\n",
    "#     params_list = BASE_LEARNERS[base_learner_type]['params']\n",
    "#     selected_params = random.sample(params_list, n)\n",
    "#     return [base_learner_class(**params) for params in selected_params], selected_params\n",
    "\n",
    "# def run_experiment():\n",
    "#     results = []\n",
    "#     configurations = []\n",
    "    \n",
    "#     for base_learner_type in BASE_LEARNERS.keys():\n",
    "#         for rep in tqdm(range(N_REPETITIONS), desc=f\"Running {base_learner_type} ensembles\"):\n",
    "#             base_learners, selected_params = create_homogeneous_ensemble(base_learner_type)\n",
    "            \n",
    "#             for method, method_params in ENSEMBLE_METHODS:\n",
    "#                 ensemble = EnsembleDetector(\n",
    "#                     base_learners=base_learners,\n",
    "#                     method=method,\n",
    "#                     method_params=method_params,\n",
    "#                     scores_dir=CACHED_SCORES_DIR\n",
    "#                 )\n",
    "                \n",
    "#                 ensemble_name = ensemble.toString()\n",
    "#                 save_results_file = os.path.join(ENSEMBLE_RESULTS_DIR, f\"{ensemble_name}_rep{rep}.csv\")\n",
    "#                 save_scores_dir = os.path.join(ENSEMBLE_SCORES_DIR, f\"{ensemble_name}_rep{rep}\")\n",
    "                \n",
    "#                 benchmark(ensemble, UCR_PATH, save_results_file, save_scores_dir)\n",
    "                \n",
    "#                 benchmark_results = pd.read_csv(save_results_file, nrows=1)\n",
    "                \n",
    "#                 result = {\n",
    "#                     'base_learner_type': base_learner_type,\n",
    "#                     'ensemble_method': method,\n",
    "#                     'method_params': json.dumps(method_params),  # Convert dict to string for storage in DataFrame\n",
    "#                     'repetition': rep,\n",
    "#                     'ucr_score': benchmark_results['accuracy'].values[0],\n",
    "#                     'computational_time': benchmark_results['total_time'].values[0]\n",
    "#                 }\n",
    "#                 results.append(result)\n",
    "                \n",
    "#                 configuration = {\n",
    "#                     'base_learner_type': base_learner_type,\n",
    "#                     'ensemble_method': method,\n",
    "#                     'method_params': method_params,\n",
    "#                     'repetition': rep,\n",
    "#                     'base_learner_params': selected_params\n",
    "#                 }\n",
    "#                 configurations.append(configuration)\n",
    "    \n",
    "#     return pd.DataFrame(results), configurations\n",
    "\n",
    "# def analyze_results(results_df):\n",
    "#     summary = results_df.groupby(['base_learner_type', 'ensemble_method', 'method_params']).agg({\n",
    "#         'ucr_score': ['mean', 'std', 'max'],\n",
    "#         'computational_time': ['mean', 'std']\n",
    "#     }).reset_index()\n",
    "    \n",
    "#     summary.columns = ['base_learner_type', 'ensemble_method', 'method_params', 'mean_score', 'std_score', 'max_score', 'mean_time', 'std_time']\n",
    "#     summary['cv_score'] = summary['std_score'] / summary['mean_score']\n",
    "    \n",
    "#     return summary\n",
    "\n",
    "# # # Run the experiment\n",
    "# # if not os.path.exists(ENSEMBLE_RESULTS_DIR):\n",
    "# #     os.makedirs(ENSEMBLE_RESULTS_DIR)\n",
    "# # if not os.path.exists(ENSEMBLE_SCORES_DIR):\n",
    "# #     os.makedirs(ENSEMBLE_SCORES_DIR)\n",
    "\n",
    "# # results_df, configurations = run_experiment()\n",
    "# # results_df.to_csv('final_experiments/experiment_e2_results.csv', index=False)\n",
    "\n",
    "# # # Save configurations\n",
    "# # with open('final_experiments/experiment_e2_configurations.json', 'w') as f:\n",
    "# #     json.dump(configurations, f, indent=2)\n",
    "\n",
    "# results_df = pd.read_csv('final_experiments/experiment_e2_results.csv')\n",
    "\n",
    "# # Analyze the results\n",
    "# summary = analyze_results(results_df)\n",
    "# summary.to_csv('final_experiments/experiment_e2_summary.csv', index=False)\n",
    "\n",
    "# print(\"Experiment E2 completed. Results saved to 'final_experiments/experiment_e2_results.csv', 'final_experiments/experiment_e2_configurations.json', and 'final_experiments/experiment_e2_summary.csv'.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the experiment\n",
    "# if not os.path.exists(ENSEMBLE_RESULTS_DIR):\n",
    "#     os.makedirs(ENSEMBLE_RESULTS_DIR)\n",
    "# if not os.path.exists(ENSEMBLE_SCORES_DIR):\n",
    "#     os.makedirs(ENSEMBLE_SCORES_DIR)\n",
    "\n",
    "# results_df, configurations = run_experiment()\n",
    "# results_df.to_csv('experiment_e2_results.csv', index=False)\n",
    "\n",
    "# # Save configurations\n",
    "# with open('experiment_e2_configurations.json', 'w') as f:\n",
    "#     json.dump(configurations, f, indent=2)\n",
    "\n",
    "# Analyze the results\n",
    "summary = analyze_results(results_df)\n",
    "summary.to_csv('experiment_e2_summary.csv', index=False)\n",
    "\n",
    "print(\"Experiment E2 completed. Results saved to 'experiment_e2_results.csv', 'experiment_e2_configurations.json', and 'experiment_e2_summary.csv'.\")\n",
    "summary = pd.read_csv('experiments/experiment_e2_summary.csv')\n",
    "\n",
    "# Compare with individual base learners from E1\n",
    "e1_results = pd.read_csv('experiments/experiment_e1_results.csv')\n",
    "e1_summary = e1_results.groupby('base_learner').agg({\n",
    "    'ucr_score': ['mean', 'std', 'max'],\n",
    "    'computational_time': ['mean', 'std']\n",
    "}).reset_index()\n",
    "e1_summary.columns = ['base_learner', 'mean_score', 'std_score', 'max_score', 'mean_time', 'std_time']\n",
    "e1_summary['cv_score'] = e1_summary['std_score'] / e1_summary['mean_score']\n",
    "\n",
    "# print(\"\\nComparison with individual base learners from E1:\")\n",
    "# print(e1_summary)\n",
    "# print(\"\\nHomogeneous ensemble summary:\")\n",
    "# print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All visualizations have been created and saved in the 'visualisations/experiment_2' directory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import json\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Updated function to create unique method names\n",
    "def get_unique_method_name(method, params):\n",
    "    if method == 'wv_ols_r2':\n",
    "        return f\"wv_ols_r2_{str(params.get('emphasize_diversity', False))[0]}\"\n",
    "    elif method == 'hard_voting':\n",
    "        return f\"hard_voting_{str(params.get('gaussian', False))[0]}\"\n",
    "    elif params:\n",
    "        param_str = '_'.join(f\"{k}_{v}\" for k, v in sorted(params.items()))\n",
    "        return f\"{method}_{param_str}\"\n",
    "    return method\n",
    "\n",
    "# Load the data\n",
    "e1_results = pd.read_csv('experiments/experiment_e1_results.csv')\n",
    "e2_results = pd.read_csv('experiments/experiment_e2_results.csv')\n",
    "e2_summary = pd.read_csv('experiments/experiment_e2_summary.csv')\n",
    "\n",
    "# Create unique method names\n",
    "e2_results['unique_method'] = e2_results.apply(lambda row: get_unique_method_name(row['ensemble_method'], json.loads(row['method_params'])), axis=1)\n",
    "e2_summary['unique_method'] = e2_summary.apply(lambda row: get_unique_method_name(row['ensemble_method'], json.loads(row['method_params'])), axis=1)\n",
    "\n",
    "# Load configurations\n",
    "with open('experiments/experiment_e2_configurations.json', 'r') as f:\n",
    "    e2_configs = json.load(f)\n",
    "\n",
    "# 1. Comparative Box Plots\n",
    "plt.figure(figsize=(20, 15))\n",
    "base_learners = e2_results['base_learner_type'].unique()\n",
    "for i, bl in enumerate(base_learners, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    data = [e1_results[e1_results['base_learner'] == bl]['ucr_score']]\n",
    "    labels = ['Individual']\n",
    "    for method in e2_results['unique_method'].unique():\n",
    "        data.append(e2_results[(e2_results['base_learner_type'] == bl) & \n",
    "                               (e2_results['unique_method'] == method)]['ucr_score'])\n",
    "        labels.append(method)\n",
    "    plt.boxplot(data, labels=labels)\n",
    "    plt.title(f'{bl} - Individual vs Ensemble Methods')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('UCR Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualisations/experiment_2/comparative_box_plots.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Performance Improvement Heatmap\n",
    "improvement_data = []\n",
    "for bl in base_learners:\n",
    "    bl_avg = e1_results[e1_results['base_learner'] == bl]['ucr_score'].mean()\n",
    "    for method in e2_summary['unique_method'].unique():\n",
    "        ensemble_avg = e2_summary[(e2_summary['base_learner_type'] == bl) & \n",
    "                                  (e2_summary['unique_method'] == method)]['mean_score'].values[0]\n",
    "        improvement = (ensemble_avg - bl_avg) / bl_avg * 100\n",
    "        improvement_data.append([bl, method, improvement])\n",
    "\n",
    "improvement_df = pd.DataFrame(improvement_data, columns=['Base Learner', 'Ensemble Method', 'Improvement'])\n",
    "improvement_pivot = improvement_df.pivot(index='Base Learner', columns='Ensemble Method', values='Improvement')\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "colors = ['#FF0000', '#FFFFFF', '#00FF00']  # Red, White, Green\n",
    "n_bins = 100  # Number of bins for color gradation\n",
    "cmap = LinearSegmentedColormap.from_list('custom', colors, N=n_bins)\n",
    "\n",
    "vmin = improvement_pivot.min().min()\n",
    "vmax = improvement_pivot.max().max()\n",
    "vcenter = 0\n",
    "\n",
    "sns.heatmap(improvement_pivot, annot=True, fmt='.2f', cmap=cmap, \n",
    "            vmin=vmin, vmax=vmax, center=vcenter)\n",
    "\n",
    "plt.title('Performance Improvement of Ensemble Methods (%)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualisations/experiment_2/performance_improvement_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Reliability Improvement Bar Chart\n",
    "plt.figure(figsize=(20, 12))\n",
    "base_learners = e1_results['base_learner'].unique()\n",
    "ensemble_methods = e2_summary['unique_method'].unique()\n",
    "\n",
    "x = np.arange(len(base_learners))\n",
    "width = 0.8 / (len(ensemble_methods) + 1)  # +1 for the individual learner bar\n",
    "\n",
    "e1_cv = e1_results.groupby('base_learner')['ucr_score'].apply(lambda x: x.std() / x.mean())\n",
    "plt.bar(x, e1_cv, width, label='Individual')\n",
    "\n",
    "for i, method in enumerate(ensemble_methods, 1):\n",
    "    cv_scores = []\n",
    "    for bl in base_learners:\n",
    "        cv = e2_summary[(e2_summary['base_learner_type'] == bl) & \n",
    "                        (e2_summary['unique_method'] == method)]['cv_score'].values\n",
    "        cv_scores.append(cv[0] if len(cv) > 0 else np.nan)\n",
    "    plt.bar(x + width * i, cv_scores, width, label=method)\n",
    "\n",
    "plt.xlabel('Base Learner Type')\n",
    "plt.ylabel('Coefficient of Variation of UCR Scores')\n",
    "plt.title('Reliability Comparison: Individual vs Ensemble Methods')\n",
    "plt.xticks(x + width * (len(ensemble_methods) / 2), base_learners)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualisations/experiment_2/reliability_improvement_bar_chart.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. Computational Time vs. Performance Scatter Plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "for bl in base_learners:\n",
    "    e1_data = e1_results[e1_results['base_learner'] == bl]\n",
    "    plt.scatter(e1_data['computational_time'], e1_data['ucr_score'], \n",
    "                label=f'{bl} (Individual)', alpha=0.7, marker='o')\n",
    "    \n",
    "    e2_data = e2_summary[e2_summary['base_learner_type'] == bl]\n",
    "    plt.scatter(e2_data['mean_time'], e2_data['mean_score'], \n",
    "                label=f'{bl} (Ensemble)', alpha=0.7, marker='^')\n",
    "\n",
    "plt.xlabel('Computational Time')\n",
    "plt.ylabel('UCR Score')\n",
    "plt.title('Performance vs Computational Time: Individual vs Ensemble Methods')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualisations/experiment_2/performance_vs_time_scatter.png')\n",
    "plt.close()\n",
    "\n",
    "# 5. Performance Relative to Constituent Learners\n",
    "relative_performance = []\n",
    "for config in e2_configs:\n",
    "    bl_type = config['base_learner_type']\n",
    "    method = config['ensemble_method']\n",
    "    rep = config['repetition']\n",
    "    constituent_scores = [e1_results[(e1_results['base_learner'] == bl_type) & \n",
    "                                     (e1_results['params'] == str(params))]['ucr_score'].values[0]\n",
    "                          for params in config['base_learner_params']]\n",
    "    avg_constituent_score = np.mean(constituent_scores)\n",
    "    unique_method = get_unique_method_name(method, config['method_params'])\n",
    "    ensemble_score = e2_results[(e2_results['base_learner_type'] == bl_type) & \n",
    "                                (e2_results['unique_method'] == unique_method) & \n",
    "                                (e2_results['repetition'] == rep)]['ucr_score'].values[0]\n",
    "    relative_score = ensemble_score / avg_constituent_score\n",
    "    relative_performance.append([bl_type, unique_method, relative_score])\n",
    "\n",
    "relative_df = pd.DataFrame(relative_performance, columns=['Base Learner', 'Ensemble Method', 'Relative Score'])\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.violinplot(x='Ensemble Method', y='Relative Score', hue='Base Learner', \n",
    "               data=relative_df, split=True)\n",
    "plt.axhline(y=1, color='r', linestyle='--')\n",
    "plt.title('Ensemble Performance Relative to Constituent Learners')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualisations/experiment_2/relative_performance_violin.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"All visualizations have been created and saved in the 'visualisations/experiment_2' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All visualisations have been created and saved in the 'visualisations/experiment_2b' directory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Helper function to create unique method names\n",
    "def get_unique_method_name(method, params):\n",
    "    if method == 'wv_ols_r2':\n",
    "        return f\"wv_ols_r2_{str(params.get('emphasize_diversity', False))[0]}\"\n",
    "    elif method == 'hard_voting':\n",
    "        return f\"hard_voting_{str(params.get('gaussian', False))[0]}\"\n",
    "    elif params:\n",
    "        param_str = '_'.join(f\"{k}_{v}\" for k, v in sorted(params.items()))\n",
    "        return f\"{method}_{param_str}\"\n",
    "    return method\n",
    "\n",
    "# Load the data\n",
    "e1_results = pd.read_csv('experiments/experiment_e1_results.csv')\n",
    "e2_results = pd.read_csv('experiments/experiment_e2_results.csv')\n",
    "e2_summary = pd.read_csv('experiments/experiment_e2_summary.csv')\n",
    "\n",
    "# Load configurations\n",
    "with open('experiments/experiment_e2_configurations.json', 'r') as f:\n",
    "    e2_configs = json.load(f)\n",
    "\n",
    "# Create unique method names\n",
    "e2_results['unique_method'] = e2_results.apply(lambda row: get_unique_method_name(row['ensemble_method'], json.loads(row['method_params'])), axis=1)\n",
    "e2_summary['unique_method'] = e2_summary.apply(lambda row: get_unique_method_name(row['ensemble_method'], json.loads(row['method_params'])), axis=1)\n",
    "\n",
    "# Calculate relative performance for each ensemble\n",
    "relative_performances = []\n",
    "for config in e2_configs:\n",
    "    bl_type = config['base_learner_type']\n",
    "    method = config['ensemble_method']\n",
    "    rep = config['repetition']\n",
    "    constituent_scores = [e1_results[(e1_results['base_learner'] == bl_type) & \n",
    "                                     (e1_results['params'] == str(params))]['ucr_score'].values[0]\n",
    "                          for params in config['base_learner_params']]\n",
    "    avg_constituent_score = np.mean(constituent_scores)\n",
    "    unique_method = get_unique_method_name(method, config['method_params'])\n",
    "    ensemble_data = e2_results[(e2_results['base_learner_type'] == bl_type) & \n",
    "                               (e2_results['unique_method'] == unique_method) & \n",
    "                               (e2_results['repetition'] == rep)]\n",
    "    ensemble_score = ensemble_data['ucr_score'].values[0]\n",
    "    computational_time = ensemble_data['computational_time'].values[0]\n",
    "    relative_score = ensemble_score / avg_constituent_score\n",
    "    relative_performances.append({\n",
    "        'base_learner_type': bl_type,\n",
    "        'unique_method': unique_method,\n",
    "        'repetition': rep,\n",
    "        'relative_score': relative_score,\n",
    "        'ensemble_score': ensemble_score,\n",
    "        'avg_constituent_score': avg_constituent_score,\n",
    "        'computational_time': computational_time\n",
    "    })\n",
    "\n",
    "relative_df = pd.DataFrame(relative_performances)\n",
    "\n",
    "\n",
    "# 1. Comparative Box Plots\n",
    "plt.figure(figsize=(20, 15))\n",
    "base_learners = e2_results['base_learner_type'].unique()\n",
    "for i, bl in enumerate(base_learners, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    # data = [e1_results[e1_results['base_learner'] == bl]['ucr_score']]\n",
    "    data = []\n",
    "    labels = []\n",
    "    for method in relative_df['unique_method'].unique():\n",
    "        data.append(relative_df[(relative_df['base_learner_type'] == bl) & \n",
    "                                (relative_df['unique_method'] == method)]['relative_score'])\n",
    "        labels.append(method)\n",
    "    plt.boxplot(data, labels=labels)\n",
    "    plt.axhline(y=1, color='r', linestyle='--')\n",
    "    plt.title(f'{bl} - Ensemble Methods')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('Relative Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualisations/experiment_2b/comparative_box_plots.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Performance Improvement Heatmap\n",
    "improvement_data = relative_df.groupby(['base_learner_type', 'unique_method'])['relative_score'].mean().reset_index()\n",
    "improvement_pivot = improvement_data.pivot(index='base_learner_type', columns='unique_method', values='relative_score')\n",
    "improvement_pivot = (improvement_pivot - 1) * 100  # Convert to percentage improvement\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "colors = ['#FF0000', '#FFFFFF', '#00FF00']  # Red, White, Green\n",
    "cmap = LinearSegmentedColormap.from_list('custom', colors, N=100)\n",
    "\n",
    "vmin = improvement_pivot.min().min()\n",
    "vmax = improvement_pivot.max().max()\n",
    "vcenter = 0\n",
    "\n",
    "sns.heatmap(improvement_pivot, annot=True, fmt='.2f', cmap=cmap, \n",
    "            vmin=vmin, vmax=vmax, center=vcenter)\n",
    "\n",
    "plt.title('Average Performance Improvement of Ensemble Methods (%)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualisations/experiment_2b/performance_improvement_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Reliability Improvement Bar Chart\n",
    "plt.figure(figsize=(20, 12))\n",
    "base_learners = e1_results['base_learner'].unique()\n",
    "ensemble_methods = relative_df['unique_method'].unique()\n",
    "\n",
    "x = np.arange(len(base_learners))\n",
    "width = 0.8 / (len(ensemble_methods) + 1)  # +1 for the individual learner bar\n",
    "\n",
    "e1_cv = e1_results.groupby('base_learner')['ucr_score'].apply(lambda x: x.std() / x.mean())\n",
    "plt.bar(x, e1_cv, width, label='Individual')\n",
    "\n",
    "for i, method in enumerate(ensemble_methods, 1):\n",
    "    cv_scores = []\n",
    "    for bl in base_learners:\n",
    "        e1_cv = e1_results.groupby('base_learner')['ucr_score'].apply(lambda x: x.std() / x.mean())\n",
    "\n",
    "        cv = relative_df[(relative_df['base_learner_type'] == bl) & \n",
    "                        (relative_df['unique_method'] == method)]['ensemble_score'].std() / \\\n",
    "            relative_df[(relative_df['base_learner_type'] == bl) & \n",
    "                        (relative_df['unique_method'] == method)]['ensemble_score'].mean()\n",
    "        cv_scores.append(cv)\n",
    "    plt.bar(x + width * i, cv_scores, width, label=method)\n",
    "\n",
    "plt.xlabel('Base Learner Type')\n",
    "plt.ylabel('Coefficient of Variation')\n",
    "plt.title('Reliability Comparison: Individual vs Ensemble Methods')\n",
    "plt.xticks(x + width * (len(ensemble_methods) / 2), base_learners)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualisations/experiment_2b/reliability_improvement_bar_chart.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. Computational Time vs. Performance Scatter Plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "for bl in base_learners:\n",
    "    e1_data = e1_results[e1_results['base_learner'] == bl]\n",
    "    plt.scatter(e1_data['computational_time'], e1_data['ucr_score'], \n",
    "                label=f'{bl} (Individual)', alpha=0.7, marker='o')\n",
    "    \n",
    "    e2_data = relative_df[relative_df['base_learner_type'] == bl]\n",
    "    plt.scatter(e2_data['computational_time'], e2_data['relative_score'], \n",
    "                label=f'{bl} (Ensemble)', alpha=0.7, marker='^')\n",
    "\n",
    "plt.xlabel('Computational Time')\n",
    "plt.ylabel('UCR Score / Relative Score')\n",
    "plt.title('Performance vs Computational Time: Individual vs Ensemble Methods')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualisations/experiment_2b/performance_vs_time_scatter.png')\n",
    "plt.close()\n",
    "\n",
    "# 5. Performance Relative to Constituent Learners (Violin Plot)\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.violinplot(x='unique_method', y='relative_score', hue='base_learner_type', \n",
    "               data=relative_df, split=True)\n",
    "plt.axhline(y=1, color='r', linestyle='--')\n",
    "plt.title('Ensemble Performance Relative to Constituent Learners')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualisations/experiment_2b/relative_performance_violin.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"All visualisations have been created and saved in the 'visualisations/experiment_2b' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_learner_type</th>\n",
       "      <th>unique_method</th>\n",
       "      <th>repetition</th>\n",
       "      <th>relative_score</th>\n",
       "      <th>ensemble_score</th>\n",
       "      <th>avg_constituent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOF</td>\n",
       "      <td>simple_average</td>\n",
       "      <td>0</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOF</td>\n",
       "      <td>maximum_score</td>\n",
       "      <td>0</td>\n",
       "      <td>1.037879</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOF</td>\n",
       "      <td>wv_ols</td>\n",
       "      <td>0</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOF</td>\n",
       "      <td>wv_ols_r2_F</td>\n",
       "      <td>0</td>\n",
       "      <td>1.098485</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOF</td>\n",
       "      <td>wv_ols_r2_T</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>MP</td>\n",
       "      <td>wv_ols</td>\n",
       "      <td>29</td>\n",
       "      <td>1.253264</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>MP</td>\n",
       "      <td>wv_ols_r2_F</td>\n",
       "      <td>29</td>\n",
       "      <td>0.535248</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>MP</td>\n",
       "      <td>wv_ols_r2_T</td>\n",
       "      <td>29</td>\n",
       "      <td>1.201044</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>MP</td>\n",
       "      <td>hard_voting_F</td>\n",
       "      <td>29</td>\n",
       "      <td>0.900783</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>MP</td>\n",
       "      <td>hard_voting_T</td>\n",
       "      <td>29</td>\n",
       "      <td>1.057441</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.3064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    base_learner_type   unique_method  repetition  relative_score  \\\n",
       "0                 LOF  simple_average           0        1.030303   \n",
       "1                 LOF   maximum_score           0        1.037879   \n",
       "2                 LOF          wv_ols           0        1.136364   \n",
       "3                 LOF     wv_ols_r2_F           0        1.098485   \n",
       "4                 LOF     wv_ols_r2_T           0        0.916667   \n",
       "..                ...             ...         ...             ...   \n",
       "835                MP          wv_ols          29        1.253264   \n",
       "836                MP     wv_ols_r2_F          29        0.535248   \n",
       "837                MP     wv_ols_r2_T          29        1.201044   \n",
       "838                MP   hard_voting_F          29        0.900783   \n",
       "839                MP   hard_voting_T          29        1.057441   \n",
       "\n",
       "     ensemble_score  avg_constituent_score  \n",
       "0             0.544                 0.5280  \n",
       "1             0.548                 0.5280  \n",
       "2             0.600                 0.5280  \n",
       "3             0.580                 0.5280  \n",
       "4             0.484                 0.5280  \n",
       "..              ...                    ...  \n",
       "835           0.384                 0.3064  \n",
       "836           0.164                 0.3064  \n",
       "837           0.368                 0.3064  \n",
       "838           0.276                 0.3064  \n",
       "839           0.324                 0.3064  \n",
       "\n",
       "[840 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relative_df[relative_df['unique_method']=='simple_average'].groupby('base_learner_type')['relative_score'].mean()\n",
    "relative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>ucr_score</th>\n",
       "      <th>computational_time</th>\n",
       "      <th>base_learner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'windowSize': 25, 'neighbors': 10, 'gpu': True}</td>\n",
       "      <td>0.572</td>\n",
       "      <td>593.591890</td>\n",
       "      <td>LOF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'windowSize': 25, 'neighbors': 20, 'gpu': True}</td>\n",
       "      <td>0.572</td>\n",
       "      <td>595.851824</td>\n",
       "      <td>LOF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'windowSize': 25, 'neighbors': 50, 'gpu': True}</td>\n",
       "      <td>0.576</td>\n",
       "      <td>604.703061</td>\n",
       "      <td>LOF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'windowSize': 25, 'neighbors': 100, 'gpu': True}</td>\n",
       "      <td>0.520</td>\n",
       "      <td>616.449885</td>\n",
       "      <td>LOF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'windowSize': 50, 'neighbors': 10, 'gpu': True}</td>\n",
       "      <td>0.572</td>\n",
       "      <td>1144.690072</td>\n",
       "      <td>LOF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  ucr_score  \\\n",
       "0   {'windowSize': 25, 'neighbors': 10, 'gpu': True}      0.572   \n",
       "1   {'windowSize': 25, 'neighbors': 20, 'gpu': True}      0.572   \n",
       "2   {'windowSize': 25, 'neighbors': 50, 'gpu': True}      0.576   \n",
       "3  {'windowSize': 25, 'neighbors': 100, 'gpu': True}      0.520   \n",
       "4   {'windowSize': 50, 'neighbors': 10, 'gpu': True}      0.572   \n",
       "\n",
       "   computational_time base_learner  \n",
       "0          593.591890          LOF  \n",
       "1          595.851824          LOF  \n",
       "2          604.703061          LOF  \n",
       "3          616.449885          LOF  \n",
       "4         1144.690072          LOF  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_learner_type</th>\n",
       "      <th>ensemble_method</th>\n",
       "      <th>method_params</th>\n",
       "      <th>repetition</th>\n",
       "      <th>ucr_score</th>\n",
       "      <th>computational_time</th>\n",
       "      <th>unique_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOF</td>\n",
       "      <td>simple_average</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>4431.247839</td>\n",
       "      <td>simple_average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOF</td>\n",
       "      <td>maximum_score</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.548</td>\n",
       "      <td>4431.594598</td>\n",
       "      <td>maximum_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOF</td>\n",
       "      <td>wv_ols</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>4443.556513</td>\n",
       "      <td>wv_ols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOF</td>\n",
       "      <td>wv_ols_r2</td>\n",
       "      <td>{\"emphasize_diversity\": false}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.580</td>\n",
       "      <td>4445.909986</td>\n",
       "      <td>wv_ols_r2_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOF</td>\n",
       "      <td>wv_ols_r2</td>\n",
       "      <td>{\"emphasize_diversity\": true}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>4446.019717</td>\n",
       "      <td>wv_ols_r2_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LOF</td>\n",
       "      <td>hard_voting</td>\n",
       "      <td>{\"spread_window\": 100, \"gaussian\": false}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560</td>\n",
       "      <td>4431.124438</td>\n",
       "      <td>hard_voting_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LOF</td>\n",
       "      <td>hard_voting</td>\n",
       "      <td>{\"spread_window\": 100, \"gaussian\": true}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.568</td>\n",
       "      <td>4431.433818</td>\n",
       "      <td>hard_voting_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LOF</td>\n",
       "      <td>simple_average</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572</td>\n",
       "      <td>3884.860332</td>\n",
       "      <td>simple_average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LOF</td>\n",
       "      <td>maximum_score</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556</td>\n",
       "      <td>3885.207293</td>\n",
       "      <td>maximum_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LOF</td>\n",
       "      <td>wv_ols</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.628</td>\n",
       "      <td>3896.149304</td>\n",
       "      <td>wv_ols</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  base_learner_type ensemble_method  \\\n",
       "0               LOF  simple_average   \n",
       "1               LOF   maximum_score   \n",
       "2               LOF          wv_ols   \n",
       "3               LOF       wv_ols_r2   \n",
       "4               LOF       wv_ols_r2   \n",
       "5               LOF     hard_voting   \n",
       "6               LOF     hard_voting   \n",
       "7               LOF  simple_average   \n",
       "8               LOF   maximum_score   \n",
       "9               LOF          wv_ols   \n",
       "\n",
       "                               method_params  repetition  ucr_score  \\\n",
       "0                                         {}           0      0.544   \n",
       "1                                         {}           0      0.548   \n",
       "2                                         {}           0      0.600   \n",
       "3             {\"emphasize_diversity\": false}           0      0.580   \n",
       "4              {\"emphasize_diversity\": true}           0      0.484   \n",
       "5  {\"spread_window\": 100, \"gaussian\": false}           0      0.560   \n",
       "6   {\"spread_window\": 100, \"gaussian\": true}           0      0.568   \n",
       "7                                         {}           1      0.572   \n",
       "8                                         {}           1      0.556   \n",
       "9                                         {}           1      0.628   \n",
       "\n",
       "   computational_time   unique_method  \n",
       "0         4431.247839  simple_average  \n",
       "1         4431.594598   maximum_score  \n",
       "2         4443.556513          wv_ols  \n",
       "3         4445.909986     wv_ols_r2_F  \n",
       "4         4446.019717     wv_ols_r2_T  \n",
       "5         4431.124438   hard_voting_F  \n",
       "6         4431.433818   hard_voting_T  \n",
       "7         3884.860332  simple_average  \n",
       "8         3885.207293   maximum_score  \n",
       "9         3896.149304          wv_ols  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_learner_type</th>\n",
       "      <th>ensemble_method</th>\n",
       "      <th>method_params</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>std_time</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>unique_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IF</td>\n",
       "      <td>hard_voting</td>\n",
       "      <td>{\"spread_window\": 100, \"gaussian\": false}</td>\n",
       "      <td>0.218667</td>\n",
       "      <td>0.013425</td>\n",
       "      <td>0.236</td>\n",
       "      <td>200.911367</td>\n",
       "      <td>28.740103</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>hard_voting_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IF</td>\n",
       "      <td>hard_voting</td>\n",
       "      <td>{\"spread_window\": 100, \"gaussian\": true}</td>\n",
       "      <td>0.213867</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>0.244</td>\n",
       "      <td>201.203889</td>\n",
       "      <td>28.728715</td>\n",
       "      <td>0.067119</td>\n",
       "      <td>hard_voting_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IF</td>\n",
       "      <td>maximum_score</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.203733</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>0.228</td>\n",
       "      <td>201.451223</td>\n",
       "      <td>28.734086</td>\n",
       "      <td>0.055035</td>\n",
       "      <td>maximum_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IF</td>\n",
       "      <td>simple_average</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.216267</td>\n",
       "      <td>0.010657</td>\n",
       "      <td>0.232</td>\n",
       "      <td>201.085239</td>\n",
       "      <td>28.736838</td>\n",
       "      <td>0.049279</td>\n",
       "      <td>simple_average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IF</td>\n",
       "      <td>wv_ols</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.193467</td>\n",
       "      <td>0.017655</td>\n",
       "      <td>0.228</td>\n",
       "      <td>214.064810</td>\n",
       "      <td>28.371239</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>wv_ols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IF</td>\n",
       "      <td>wv_ols_r2</td>\n",
       "      <td>{\"emphasize_diversity\": false}</td>\n",
       "      <td>0.194133</td>\n",
       "      <td>0.017663</td>\n",
       "      <td>0.228</td>\n",
       "      <td>215.275391</td>\n",
       "      <td>28.123383</td>\n",
       "      <td>0.090984</td>\n",
       "      <td>wv_ols_r2_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IF</td>\n",
       "      <td>wv_ols_r2</td>\n",
       "      <td>{\"emphasize_diversity\": true}</td>\n",
       "      <td>0.205733</td>\n",
       "      <td>0.023293</td>\n",
       "      <td>0.248</td>\n",
       "      <td>215.401882</td>\n",
       "      <td>27.774810</td>\n",
       "      <td>0.113218</td>\n",
       "      <td>wv_ols_r2_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>hard_voting</td>\n",
       "      <td>{\"spread_window\": 100, \"gaussian\": false}</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.047321</td>\n",
       "      <td>0.524</td>\n",
       "      <td>3766.828459</td>\n",
       "      <td>1122.969759</td>\n",
       "      <td>0.110908</td>\n",
       "      <td>hard_voting_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>hard_voting</td>\n",
       "      <td>{\"spread_window\": 100, \"gaussian\": true}</td>\n",
       "      <td>0.424133</td>\n",
       "      <td>0.048258</td>\n",
       "      <td>0.512</td>\n",
       "      <td>3767.096025</td>\n",
       "      <td>1122.969468</td>\n",
       "      <td>0.113780</td>\n",
       "      <td>hard_voting_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>maximum_score</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.349733</td>\n",
       "      <td>0.034914</td>\n",
       "      <td>0.436</td>\n",
       "      <td>3767.332442</td>\n",
       "      <td>1122.962086</td>\n",
       "      <td>0.099829</td>\n",
       "      <td>maximum_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>simple_average</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.428933</td>\n",
       "      <td>0.036125</td>\n",
       "      <td>0.504</td>\n",
       "      <td>3766.997227</td>\n",
       "      <td>1122.967656</td>\n",
       "      <td>0.084221</td>\n",
       "      <td>simple_average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>wv_ols</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.422133</td>\n",
       "      <td>0.062480</td>\n",
       "      <td>0.540</td>\n",
       "      <td>3778.376136</td>\n",
       "      <td>1122.783752</td>\n",
       "      <td>0.148009</td>\n",
       "      <td>wv_ols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>wv_ols_r2</td>\n",
       "      <td>{\"emphasize_diversity\": false}</td>\n",
       "      <td>0.396533</td>\n",
       "      <td>0.049813</td>\n",
       "      <td>0.480</td>\n",
       "      <td>3779.751194</td>\n",
       "      <td>1122.940785</td>\n",
       "      <td>0.125622</td>\n",
       "      <td>wv_ols_r2_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KMeans</td>\n",
       "      <td>wv_ols_r2</td>\n",
       "      <td>{\"emphasize_diversity\": true}</td>\n",
       "      <td>0.338533</td>\n",
       "      <td>0.042351</td>\n",
       "      <td>0.444</td>\n",
       "      <td>3779.313848</td>\n",
       "      <td>1122.995402</td>\n",
       "      <td>0.125102</td>\n",
       "      <td>wv_ols_r2_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LOF</td>\n",
       "      <td>hard_voting</td>\n",
       "      <td>{\"spread_window\": 100, \"gaussian\": false}</td>\n",
       "      <td>0.589333</td>\n",
       "      <td>0.027197</td>\n",
       "      <td>0.632</td>\n",
       "      <td>3983.867863</td>\n",
       "      <td>638.671136</td>\n",
       "      <td>0.046149</td>\n",
       "      <td>hard_voting_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LOF</td>\n",
       "      <td>hard_voting</td>\n",
       "      <td>{\"spread_window\": 100, \"gaussian\": true}</td>\n",
       "      <td>0.586133</td>\n",
       "      <td>0.028240</td>\n",
       "      <td>0.640</td>\n",
       "      <td>3984.159234</td>\n",
       "      <td>638.672787</td>\n",
       "      <td>0.048180</td>\n",
       "      <td>hard_voting_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LOF</td>\n",
       "      <td>maximum_score</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.522000</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>0.584</td>\n",
       "      <td>3984.410092</td>\n",
       "      <td>638.667072</td>\n",
       "      <td>0.060496</td>\n",
       "      <td>maximum_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LOF</td>\n",
       "      <td>simple_average</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.585867</td>\n",
       "      <td>0.036202</td>\n",
       "      <td>0.632</td>\n",
       "      <td>3984.037912</td>\n",
       "      <td>638.675047</td>\n",
       "      <td>0.061793</td>\n",
       "      <td>simple_average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LOF</td>\n",
       "      <td>wv_ols</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.584933</td>\n",
       "      <td>0.030871</td>\n",
       "      <td>0.628</td>\n",
       "      <td>3998.732093</td>\n",
       "      <td>638.514630</td>\n",
       "      <td>0.052777</td>\n",
       "      <td>wv_ols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LOF</td>\n",
       "      <td>wv_ols_r2</td>\n",
       "      <td>{\"emphasize_diversity\": false}</td>\n",
       "      <td>0.553867</td>\n",
       "      <td>0.035416</td>\n",
       "      <td>0.608</td>\n",
       "      <td>4000.473066</td>\n",
       "      <td>638.447056</td>\n",
       "      <td>0.063944</td>\n",
       "      <td>wv_ols_r2_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LOF</td>\n",
       "      <td>wv_ols_r2</td>\n",
       "      <td>{\"emphasize_diversity\": true}</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.053589</td>\n",
       "      <td>0.584</td>\n",
       "      <td>4000.487731</td>\n",
       "      <td>638.257562</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>wv_ols_r2_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MP</td>\n",
       "      <td>hard_voting</td>\n",
       "      <td>{\"spread_window\": 100, \"gaussian\": false}</td>\n",
       "      <td>0.387733</td>\n",
       "      <td>0.111496</td>\n",
       "      <td>0.564</td>\n",
       "      <td>621.375350</td>\n",
       "      <td>7.525179</td>\n",
       "      <td>0.287559</td>\n",
       "      <td>hard_voting_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MP</td>\n",
       "      <td>hard_voting</td>\n",
       "      <td>{\"spread_window\": 100, \"gaussian\": true}</td>\n",
       "      <td>0.432267</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.564</td>\n",
       "      <td>621.633483</td>\n",
       "      <td>7.520895</td>\n",
       "      <td>0.213544</td>\n",
       "      <td>hard_voting_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MP</td>\n",
       "      <td>maximum_score</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.262400</td>\n",
       "      <td>0.071017</td>\n",
       "      <td>0.476</td>\n",
       "      <td>621.838691</td>\n",
       "      <td>7.530140</td>\n",
       "      <td>0.270644</td>\n",
       "      <td>maximum_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MP</td>\n",
       "      <td>simple_average</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.556400</td>\n",
       "      <td>0.062767</td>\n",
       "      <td>0.636</td>\n",
       "      <td>621.526914</td>\n",
       "      <td>7.524823</td>\n",
       "      <td>0.112809</td>\n",
       "      <td>simple_average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MP</td>\n",
       "      <td>wv_ols</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.105684</td>\n",
       "      <td>0.620</td>\n",
       "      <td>632.639931</td>\n",
       "      <td>7.654213</td>\n",
       "      <td>0.223907</td>\n",
       "      <td>wv_ols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MP</td>\n",
       "      <td>wv_ols_r2</td>\n",
       "      <td>{\"emphasize_diversity\": false}</td>\n",
       "      <td>0.372267</td>\n",
       "      <td>0.135479</td>\n",
       "      <td>0.580</td>\n",
       "      <td>635.302532</td>\n",
       "      <td>7.750046</td>\n",
       "      <td>0.363931</td>\n",
       "      <td>wv_ols_r2_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MP</td>\n",
       "      <td>wv_ols_r2</td>\n",
       "      <td>{\"emphasize_diversity\": true}</td>\n",
       "      <td>0.301733</td>\n",
       "      <td>0.094264</td>\n",
       "      <td>0.564</td>\n",
       "      <td>635.155982</td>\n",
       "      <td>7.513169</td>\n",
       "      <td>0.312409</td>\n",
       "      <td>wv_ols_r2_T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   base_learner_type ensemble_method  \\\n",
       "0                 IF     hard_voting   \n",
       "1                 IF     hard_voting   \n",
       "2                 IF   maximum_score   \n",
       "3                 IF  simple_average   \n",
       "4                 IF          wv_ols   \n",
       "5                 IF       wv_ols_r2   \n",
       "6                 IF       wv_ols_r2   \n",
       "7             KMeans     hard_voting   \n",
       "8             KMeans     hard_voting   \n",
       "9             KMeans   maximum_score   \n",
       "10            KMeans  simple_average   \n",
       "11            KMeans          wv_ols   \n",
       "12            KMeans       wv_ols_r2   \n",
       "13            KMeans       wv_ols_r2   \n",
       "14               LOF     hard_voting   \n",
       "15               LOF     hard_voting   \n",
       "16               LOF   maximum_score   \n",
       "17               LOF  simple_average   \n",
       "18               LOF          wv_ols   \n",
       "19               LOF       wv_ols_r2   \n",
       "20               LOF       wv_ols_r2   \n",
       "21                MP     hard_voting   \n",
       "22                MP     hard_voting   \n",
       "23                MP   maximum_score   \n",
       "24                MP  simple_average   \n",
       "25                MP          wv_ols   \n",
       "26                MP       wv_ols_r2   \n",
       "27                MP       wv_ols_r2   \n",
       "\n",
       "                                method_params  mean_score  std_score  \\\n",
       "0   {\"spread_window\": 100, \"gaussian\": false}    0.218667   0.013425   \n",
       "1    {\"spread_window\": 100, \"gaussian\": true}    0.213867   0.014354   \n",
       "2                                          {}    0.203733   0.011212   \n",
       "3                                          {}    0.216267   0.010657   \n",
       "4                                          {}    0.193467   0.017655   \n",
       "5              {\"emphasize_diversity\": false}    0.194133   0.017663   \n",
       "6               {\"emphasize_diversity\": true}    0.205733   0.023293   \n",
       "7   {\"spread_window\": 100, \"gaussian\": false}    0.426667   0.047321   \n",
       "8    {\"spread_window\": 100, \"gaussian\": true}    0.424133   0.048258   \n",
       "9                                          {}    0.349733   0.034914   \n",
       "10                                         {}    0.428933   0.036125   \n",
       "11                                         {}    0.422133   0.062480   \n",
       "12             {\"emphasize_diversity\": false}    0.396533   0.049813   \n",
       "13              {\"emphasize_diversity\": true}    0.338533   0.042351   \n",
       "14  {\"spread_window\": 100, \"gaussian\": false}    0.589333   0.027197   \n",
       "15   {\"spread_window\": 100, \"gaussian\": true}    0.586133   0.028240   \n",
       "16                                         {}    0.522000   0.031579   \n",
       "17                                         {}    0.585867   0.036202   \n",
       "18                                         {}    0.584933   0.030871   \n",
       "19             {\"emphasize_diversity\": false}    0.553867   0.035416   \n",
       "20              {\"emphasize_diversity\": true}    0.502400   0.053589   \n",
       "21  {\"spread_window\": 100, \"gaussian\": false}    0.387733   0.111496   \n",
       "22   {\"spread_window\": 100, \"gaussian\": true}    0.432267   0.092308   \n",
       "23                                         {}    0.262400   0.071017   \n",
       "24                                         {}    0.556400   0.062767   \n",
       "25                                         {}    0.472000   0.105684   \n",
       "26             {\"emphasize_diversity\": false}    0.372267   0.135479   \n",
       "27              {\"emphasize_diversity\": true}    0.301733   0.094264   \n",
       "\n",
       "    max_score    mean_time     std_time  cv_score   unique_method  \n",
       "0       0.236   200.911367    28.740103  0.061395   hard_voting_F  \n",
       "1       0.244   201.203889    28.728715  0.067119   hard_voting_T  \n",
       "2       0.228   201.451223    28.734086  0.055035   maximum_score  \n",
       "3       0.232   201.085239    28.736838  0.049279  simple_average  \n",
       "4       0.228   214.064810    28.371239  0.091257          wv_ols  \n",
       "5       0.228   215.275391    28.123383  0.090984     wv_ols_r2_F  \n",
       "6       0.248   215.401882    27.774810  0.113218     wv_ols_r2_T  \n",
       "7       0.524  3766.828459  1122.969759  0.110908   hard_voting_F  \n",
       "8       0.512  3767.096025  1122.969468  0.113780   hard_voting_T  \n",
       "9       0.436  3767.332442  1122.962086  0.099829   maximum_score  \n",
       "10      0.504  3766.997227  1122.967656  0.084221  simple_average  \n",
       "11      0.540  3778.376136  1122.783752  0.148009          wv_ols  \n",
       "12      0.480  3779.751194  1122.940785  0.125622     wv_ols_r2_F  \n",
       "13      0.444  3779.313848  1122.995402  0.125102     wv_ols_r2_T  \n",
       "14      0.632  3983.867863   638.671136  0.046149   hard_voting_F  \n",
       "15      0.640  3984.159234   638.672787  0.048180   hard_voting_T  \n",
       "16      0.584  3984.410092   638.667072  0.060496   maximum_score  \n",
       "17      0.632  3984.037912   638.675047  0.061793  simple_average  \n",
       "18      0.628  3998.732093   638.514630  0.052777          wv_ols  \n",
       "19      0.608  4000.473066   638.447056  0.063944     wv_ols_r2_F  \n",
       "20      0.584  4000.487731   638.257562  0.106667     wv_ols_r2_T  \n",
       "21      0.564   621.375350     7.525179  0.287559   hard_voting_F  \n",
       "22      0.564   621.633483     7.520895  0.213544   hard_voting_T  \n",
       "23      0.476   621.838691     7.530140  0.270644   maximum_score  \n",
       "24      0.636   621.526914     7.524823  0.112809  simple_average  \n",
       "25      0.620   632.639931     7.654213  0.223907          wv_ols  \n",
       "26      0.580   635.302532     7.750046  0.363931     wv_ols_r2_F  \n",
       "27      0.564   635.155982     7.513169  0.312409     wv_ols_r2_T  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: \n",
    "when evaluating ensembles, we did not recompute the base learner anomaly score predictions. Instead, we simply extracted the relevant scores from the scores cached in Experiment 1.  The primary reason for this was computational cost.  This is a valid approach since none of the aggregation functions are dependent i.e. they do not have to be trained in sequence with the consitutent base learners.  However, this does mean that we did not record the _direct_ processing time per time series for any of the ensemble detectors.  Instead, we assumed that the base learners would make inference on the data in parallel, and took the score of the longest base learner plus the time for aggregation, as the processing time for the ensemble learner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRUCIAL LIMITATION:\n",
    "\n",
    "The computational time comparison between individual learners and ensembles may not be entirely fair. The ensemble processing times are not directly measured but estimated based on the longest base learner time plus aggregation time. This approach assumes parallel processing of base learners, which may not always be possible or practical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully appended to final_experiments/demo.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_503469/337232195.py:71: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([existing_data, new_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Define the directory and file paths\n",
    "input_dir = 'final_ensembles/results/'\n",
    "output_file = 'final_experiments/demo.csv'\n",
    "\n",
    "# Read existing data\n",
    "existing_data = pd.read_csv(output_file)\n",
    "\n",
    "# List to store new data\n",
    "new_data = []\n",
    "\n",
    "# Regular expression pattern to match desired files\n",
    "pattern = r'ensemble_hom_(lof|if)_(.+)_rep([0-9])\\.csv'\n",
    "\n",
    "# Function to get method and params\n",
    "def get_method_and_params(method_string):\n",
    "    if method_string == 'simple_average':\n",
    "        return 'simple_average', '{}'\n",
    "    elif method_string == 'maximum_score':\n",
    "        return 'maximum_score', '{}'\n",
    "    elif method_string == 'wv_ols':\n",
    "        return 'wv_ols', '{}'\n",
    "    elif method_string.startswith('wv_ols_r2'):\n",
    "        emphasize_diversity = method_string.endswith('_t')\n",
    "        return 'wv_ols_r2', json.dumps({\"emphasize_diversity\": emphasize_diversity})\n",
    "    elif method_string.startswith('hard_voting'):\n",
    "        gaussian = method_string.endswith('_gaussian')\n",
    "        return 'hard_voting', json.dumps({\"spread_window\": 100, \"gaussian\": gaussian})\n",
    "    else:\n",
    "        return method_string, '{}'  # Default case\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    match = re.match(pattern, filename)\n",
    "    if match and int(match.group(3)) < 10:  # Check if repetition is 0-9\n",
    "        base_learner_type = match.group(1).upper()\n",
    "        method_string = match.group(2)\n",
    "        repetition = int(match.group(3))\n",
    "\n",
    "        with open(os.path.join(input_dir, filename), 'r') as file:\n",
    "            # Read the first line (header) and split it\n",
    "            header = file.readline().strip().split(',')\n",
    "            # Read the second line (data) and split it\n",
    "            data = file.readline().strip().split(',')\n",
    "            \n",
    "            # Extract relevant information\n",
    "            computational_time = float(data[1])\n",
    "            ucr_score = float(data[2])\n",
    "            \n",
    "            # Get method and params\n",
    "            ensemble_method, method_params = get_method_and_params(method_string)\n",
    "            \n",
    "            # Append to new_data list\n",
    "            new_data.append({\n",
    "                'base_learner_type': base_learner_type,\n",
    "                'ensemble_method': ensemble_method,\n",
    "                'method_params': method_params,\n",
    "                'repetition': repetition,\n",
    "                'ucr_score': ucr_score,\n",
    "                'computational_time': computational_time\n",
    "            })\n",
    "\n",
    "# Convert new_data to DataFrame\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Append new data to existing data\n",
    "combined_df = pd.concat([existing_data, new_df], ignore_index=True)\n",
    "\n",
    "# Save the combined data back to the CSV file\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data has been successfully appended to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(output_file)\n",
    "sorted_data = data.sort_values(by=['base_learner_type', 'repetition', 'ensemble_method'])\n",
    "sorted_data.to_csv('demo_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
